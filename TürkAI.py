import streamlit as st
import requests
from bs4 import BeautifulSoup
import random
import re
from fpdf import FPDF

# --- ğŸ§  SÄ°STEM HAFIZASI ---
if "giris_yapildi" not in st.session_state:
    st.session_state.giris_yapildi = False
if "kullanici_adi" not in st.session_state:
    st.session_state.kullanici_adi = ""
if "gecmis" not in st.session_state:
    st.session_state.gecmis = []

# --- ğŸ§¹ SÃœPER TEMÄ°ZLÄ°K ARACI (Soru Ä°ÅŸareti DÃ¼ÅŸmanÄ±) ---
def metni_temizle(metin):
    # 1. Wikipedia kaynak numaralarÄ±nÄ± siler: [1], [22]
    metin = re.sub(r'\[\d+\]', '', metin)
    
    # 2. PDF'in tanÄ±madÄ±ÄŸÄ± Yunanca ve Ã¶zel sembolleri ayÄ±klar (Sadece standart karakterleri bÄ±rakÄ±r)
    # Bu kÄ±sÄ±m (Yunanca: Ï„Î­Ï‡Î½Î·) gibi kÄ±sÄ±mlardaki yabancÄ± harfleri temizler
    metin = re.sub(r'[^\x00-\x7f\x80-\xff]', '', metin)
    
    # 3. Gizli boÅŸluk karakterlerini (non-breaking space vb.) normal boÅŸluÄŸa Ã§evirir
    metin = metin.replace('\xa0', ' ').replace('\u200b', '')
    
    return metin.strip()

# --- ğŸ“„ PDF OLUÅTURUCU (HatasÄ±z Mod) ---
def pdf_olustur(baslik, icerik, kullanici):
    pdf = FPDF()
    pdf.add_page()
    
    # PDF iÃ§inde soru iÅŸareti Ã§Ä±kmamasÄ± iÃ§in gÃ¼venli karakter dÃ¶nÃ¼ÅŸÃ¼mÃ¼
    def gÃ¼venli_yazi(s):
        # Latin-1'e uymayan her ÅŸeyi temizle veya soru iÅŸaretine dÃ¶nÃ¼ÅŸtÃ¼rmeden yok et
        return s.encode('latin-1', 'ignore').decode('latin-1')

    pdf.set_font("Arial", "B", 16)
    pdf.cell(200, 10, txt="TurkAI Arastirma Raporu", ln=True, align='C')
    pdf.ln(10)
    
    pdf.set_font("Arial", size=12)
    pdf.cell(200, 10, txt=gÃ¼venli_yazi(f"Konu: {baslik}"), ln=True)
    pdf.cell(200, 10, txt=gÃ¼venli_yazi(f"Arastirmaci: {kullanici}"), ln=True)
    pdf.ln(5)
    
    # Metni satÄ±rlara bÃ¶lerek yazdÄ±r
    pdf.multi_cell(0, 8, txt=gÃ¼venli_yazi(icerik))
    return pdf.output(dest='S').encode('latin-1')

# --- ğŸ¨ TEMA ---
def yerel_css():
    st.markdown("""
        <style>
        .stButton>button { background-color: #e63946; color: white; border-radius: 8px; font-weight: bold; }
        .stTextInput>div>div>input { border: 2px solid #e63946; border-radius: 8px; }
        h1 { color: #e63946; text-align: center; border-bottom: 2px solid #e63946; padding-bottom: 10px; }
        </style>
    """, unsafe_allow_html=True)

# --- ğŸšª GÄ°RÄ°Å ---
if not st.session_state.giris_yapildi:
    st.set_page_config(page_title="TÃ¼rkAI GiriÅŸ", page_icon="ğŸ‡¹ğŸ‡·")
    yerel_css()
    st.title("ğŸ‡¹ğŸ‡· TÃ¼rkAI Analiz Sistemi")
    isim = st.text_input("KullanÄ±cÄ± AdÄ±nÄ±z:", placeholder="Ã–rn: Kaptan")
    if st.button("Sisteme GiriÅŸ"):
        if len(isim) >= 2:
            st.session_state.kullanici_adi = isim
            st.session_state.giris_yapildi = True
            st.rerun()
    st.stop()

# --- ğŸš€ ANA EKRAN ---
st.set_page_config(page_title="TÃ¼rkAI v45.0", page_icon="ğŸ‡¹ğŸ‡·", layout="wide")
yerel_css()

# YAN PANEL
st.sidebar.title("ğŸ›¡ï¸ TÃ¼rkAI Kontrol")
st.sidebar.info(f"ğŸ‘¤ AraÅŸtÄ±rmacÄ±: {st.session_state.kullanici_adi}")
if st.sidebar.button("Ã‡Ä±kÄ±ÅŸ"):
    st.session_state.giris_yapildi = False
    st.rerun()

# ARAÅTIRMA BÃ–LÃœMÃœ
st.title("ğŸ” Profesyonel AraÅŸtÄ±rma HattÄ±")

KARA_LISTE = ["amk", "aq", "piÃ§", "oÃ§", "sg", "sik", "yarrak", "gÃ¶t"]
konu = st.text_input("Hangi konuyu derinlemesine analiz edelim?", placeholder="Ã–rn: Teknoloji")

if st.button("Analizi BaÅŸlat"):
    if konu and not any(k in konu.lower() for k in KARA_LISTE):
        with st.spinner("Veriler ayÄ±klanÄ±yor ve yabancÄ± semboller temizleniyor..."):
            arama_linki = konu.strip().capitalize().replace(' ', '_')
            url = f"https://tr.wikipedia.org/wiki/{arama_linki}"
            try:
                r = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
                if r.status_code == 200:
                    soup = BeautifulSoup(r.text, 'html.parser')
                    # TÃ¼m paragraflarÄ± al ve her birini temizle
                    paragraflar = [metni_temizle(p.get_text()) for p in soup.find_all('p') if len(p.get_text()) > 40]
                    
                    if paragraflar:
                        if konu not in st.session_state.gecmis:
                            st.session_state.gecmis.append(konu)
                        
                        st.success(f"âœ… {konu} analizi hazÄ±r.")
                        
                        # Ã–zet (Ä°lk Paragraf)
                        st.subheader("ğŸ“Œ Ã–zet Bilgi")
                        st.info(paragraflar[0])
                        
                        # Hepsini GÃ¶ster (Detaylar)
                        tam_metin = "\n\n".join(paragraflar[:15]) # Ä°lk 15 paragrafÄ± al
                        with st.expander("ğŸ“– TÃ¼m DetaylÄ± Analizi GÃ¶r"):
                            st.write(tam_metin)
                        
                        # PDF Ä°NDÄ°RME (TemizlenmiÅŸ Metinle)
                        pdf_data = pdf_olustur(konu, tam_metin[:4000], st.session_state.kullanici_adi)
                        st.download_button("ğŸ“„ TemizlenmiÅŸ Raporu PDF Ä°ndir", pdf_data, f"{konu}_Arastirma.pdf", "application/pdf")
                    else:
                        st.warning("Yeterli veri bulunamadÄ±.")
                else:
                    st.error("Konu baÅŸlÄ±ÄŸÄ± Wikipedia'da bulunamadÄ±.")
            except:
                st.error("BaÄŸlantÄ± hatasÄ± oluÅŸtu.")
    elif konu:
        st.error("âš ï¸ LÃ¼tfen uygun bir baÅŸlÄ±k giriniz.")

st.sidebar.divider()
st.sidebar.write("**Arama GeÃ§miÅŸi:**")
for g in st.session_state.gecmis[-5:]:
    st.sidebar.caption(f"â€¢ {g}")



